# ONCE-FOR-ALL: TRAIN ONE NETWORK AND SPECIALIZE IT FOR EFFICIENT DEPLOYMENT
Han Cai, Chuang Gan, TianzheWang, Zhekai Zhang, Song Han
## Introduction
提出once-for-all网络。推理过程将只选择网络的一部分进行。具体地，将模型训练阶段和结构搜索阶段分离。在训练阶段，关注提升所有子网络的性能，自网络通过选择ofa
网络的不同部分得到。在模型具体化阶段，选择一个子网络来训练准确率预测器和时延预测器。  
提出一个渐进收缩算法以训练ofa网络，先训练最大的网络，然后渐进的finetune以支持小网络。  
## Method
1. **问题建模**  
设ofa网络的参数为W<sub>o</sub>，结构确认为{arch<sub>i</sub>}，问题可以表征为  
<img src="https://latex.codecogs.com/gif.latex?\min_W_o\sum_{arch_i}L_{val}(C(W_o,arch_i))" title="\min_W_o\sum_{arch_i}L_{val}(C(W_o,arch_i))" />  
C(W<sub>o</sub>,arch_i)表示从ofa中选出的子网络，整体的训练目标是优化W<sub>o</sub>来使每个子网络达到与独立训练是相同的准确率。 

2. **结构空间**  
略  
3. **训练ofa网络**  
ofa网络包含了许多不同大小的子网络，为了防止子网络之间的相互干扰，提出一个强制从大子网络到小子网络的渐进策略，称为渐进收缩。从训练最大的网络（最深、最宽、
卷积核最大），逐渐finetune网络以使其支持更小的子网络，通过逐渐把他们加入到采样空间。具体地，在训练大网络之后，保持深度和宽度不变，将卷积核设为可选择（3,5,7）
然后支持弹性的深度和宽度，分辨率在整个训练过程都是弹性的，通过对每一批数据采样不同图像尺寸来实现。训练完大网络后使用知识蒸馏策略。  
具体方案：  
* 弹性卷积核。我们让7X7卷积核的中心也可以作为5X5的核，5x5的中心也可作为3X3的核。挑战在于，中间的卷积核是共享的，且扮演不同的角色（独立的小卷积核，和大卷积核的一部分）
我们在共享卷积核参数的时候使用核变换矩阵，在每一层，不同通道的核变换矩阵是共享的。因此需要25X25+9X9=706个额外参数。  
* 弹性深度。为了从N层ofa网络得到一个D层的子网络，保持前D层，跳过后N-D层，而不是任意选择D层，这样，一种深度设置只对应一种层的组合。  
* 弹性宽度。先训练full-width的网络，然后通过通道排序操作来支持更小的宽度。通道排序根据通道的重要性重组，重要性由通道的L1范数计算。例如，从4通道向3通道收缩
时，取重要性最大的三个通道  
4. **使用ofa网络部署具体的网络**  
目标是在优化准确率的同时搜索出考虑时延的模型。简历neural-network-twins来预测给定结构的准确率和时延。将测量得到的准确率和时延替换为预测得到的准确率和时延（twins）将
减少重复地搜索消耗。  
具体地，我们随机采样了16k个不同结构的子网络，和输入尺寸，测试他们在10k验证图片（从训练集中选取）上的准确率，这些【结构，准确率】pair将用以训练一个准确率
预测器，接收结构和输入尺寸作为输入，输出准确率预测值。通过建立查找表来预测时延。给定目标终端和时延约束，使用进化搜索算法来实例化一个子网络


